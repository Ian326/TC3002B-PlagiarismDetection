{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PlagiarismDetection\n",
    "---\n",
    "\n",
    "Plagiarism detection tool designed to analyze source code files. [Supporting Java Language]\n",
    "\n",
    "\n",
    "**Authors**\n",
    "* José Armando Rosas Balderas | A01704132\n",
    "* Ramona Najera Fuentes       | A01423596\n",
    "* Ian Joab Padron Corona      | A01708940"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "AST Parser\n",
    "--------------------------------------------------------------------------------------------------\n",
    "This file contains the code to parse the AST of a given code snippet using tree-sitter.\n",
    "\n",
    "Authors\n",
    "--------------------------------------------------------------------------------------------------\n",
    "  * José Armando Rosas Balderas | A01704132\n",
    "  * Ramona Najera Fuentes       | A01423596\n",
    "  * Ian Joab Padron Corona      | A01708940\n",
    "\n",
    "**Date:** 2025-Apr-28\n",
    "\n",
    "Libraries\n",
    "--------------------------------------------------------------------------------------------------\n",
    "`tree-stitter`: Library for parsing source code into an AST.\n",
    "`numpy`: Library for numerical computations in Python.\n",
    "`matplotlib`: Library for creating static, animated, and interactive visualizations in Python.\n",
    "`sys`: Library for system-specific parameters and functions.\n",
    "`networkx`: Library for creating and manipulating complex networks.\n",
    "`warnings`: Library for issuing warning messages.\n",
    "\n",
    "\n",
    "Usage\n",
    "--------------------------------------------------------------------------------------------------\n",
    "This script is used to parse the AST of a given code snippet using tree-sitter.\n",
    "```\n",
    "python AST.py <lang_grammar> <path_grammar> <file>\n",
    "```\n",
    "'''\n",
    "from tree_sitter import Language, Parser\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import networkx as nx\n",
    "import warnings\n",
    "\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfs_ast(node, level=0, node_list=None):\n",
    "  \"\"\"\n",
    "  Perform a depth-first search (DFS) on the AST and store the nodes in a list. \n",
    "  Preorder traversal is used to visit the nodes.\n",
    "\n",
    "  Parameters\n",
    "  ---\n",
    "  node: `Tree Sitter Node` The current node in the AST.\n",
    "\n",
    "  level: `int` The current level in the tree. Default is 0.\n",
    "\n",
    "  node_list: `list` The list to store the nodes. Default is None.\n",
    "\n",
    "  Returns\n",
    "  ---\n",
    "  node_list: `list` The list of nodes in the AST.\n",
    "  \"\"\"\n",
    "  \n",
    "  if node_list is None:\n",
    "      node_list = []\n",
    "  \n",
    "  node_list.append((node.type, level))\n",
    "\n",
    "  # Recursively process child nodes\n",
    "  for child in node.children:\n",
    "      dfs_ast(child, level + 1, node_list)\n",
    "  \n",
    "  return node_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9579a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchy_pos(cfgGraph, root, width=15., vert_gap=0.5, vert_loc=0, xcenter=0.5):\n",
    "    \"\"\"\n",
    "    Position nodes in a hierarchy layout with increased spacing between nodes at the same level.\n",
    "\n",
    "    Parameters\n",
    "    ---\n",
    "    cfgGraph: `Graph` The graph to be laid out.\n",
    "    root: `Node` The root node of the hierarchy.\n",
    "    width: `float` The width of the layout. Default is 2.0 for more spacing.\n",
    "    vert_gap: `float` The vertical gap between nodes.\n",
    "    vert_loc: `float` The vertical location of the root node.\n",
    "    xcenter: `float` The horizontal center of the layout.\n",
    "\n",
    "    Returns\n",
    "    ---\n",
    "    pos: `dict` A dictionary mapping nodes to their positions in the layout.\n",
    "    \"\"\"\n",
    "    def _hierarchy_pos(cfgGraph, root, leftmost, width, vert_gap, vert_loc, xcenter, pos, parent=None):\n",
    "        children = list(cfgGraph.successors(root))\n",
    "\n",
    "        if not children:\n",
    "            pos[root] = (leftmost[0], vert_loc)\n",
    "            leftmost[0] += width\n",
    "        else:\n",
    "            for child in children:\n",
    "                pos = _hierarchy_pos(cfgGraph, child, leftmost, width, vert_gap, vert_loc - vert_gap, xcenter, pos, root)\n",
    "            mid = (pos[children[0]][0] + pos[children[-1]][0]) / 2\n",
    "            pos[root] = (mid, vert_loc)\n",
    "\n",
    "        return pos\n",
    "\n",
    "    return _hierarchy_pos(cfgGraph, root, [0], width, vert_gap, vert_loc, xcenter, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AST_toGraph(graph, node, parent=None, counter=[0]):\n",
    "    \"\"\"\n",
    "    Recursively build a graph from a Tree-sitter node\n",
    "\n",
    "    Parameters\n",
    "    ---\n",
    "    \n",
    "    graph: `Graph` The graph to be built.\n",
    "    \n",
    "    node: `Tree Sitter Node` The current node in the AST.\n",
    "    \n",
    "    parent: `Node` The parent node of the current node. Default is None.\n",
    "    \n",
    "    counter: `list` A list to keep track of the node index. Default is [0].\n",
    "    \n",
    "    Returns\n",
    "    ---\n",
    "    graph: `Graph` The graph built from the Tree-sitter node.\n",
    "    \"\"\"\n",
    "    \n",
    "    idx = counter[0]\n",
    "    label = node.type\n",
    "    \n",
    "    if node.child_count == 0:\n",
    "        label += f\": {node.text.decode('utf8')}\"\n",
    "    graph.add_node(idx, label=label)\n",
    "\n",
    "    if parent is not None:\n",
    "        graph.add_edge(parent, idx)\n",
    "\n",
    "    counter[0] += 1\n",
    "    \n",
    "    for child in node.children:\n",
    "        AST_toGraph(graph, child, idx, counter)\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printTreeNodes(nodes_list):\n",
    "    \"\"\"\n",
    "    Print the nodes of the AST in a readable format with tabulations to represent the tree structure.\n",
    "\n",
    "    Parameters\n",
    "    ---\n",
    "    nodes_list: `list` The list of nodes in the AST.\n",
    "    \"\"\"\n",
    "    for node_type, level in nodes_list:\n",
    "        print(f\"{'· ' * level}{node_type}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFGBuilder:\n",
    "    \"\"\"\n",
    "    Class to build a Control Flow Graph (CFG) from a given code snippet using tree-sitter.\n",
    "\n",
    "    Parameters\n",
    "    ---\n",
    "    code: `bytes` The code snippet to be parsed.\n",
    "    \"\"\"\n",
    "    def __init__(self, code: bytes):\n",
    "        self.graph = nx.DiGraph()\n",
    "        self.counter = 0\n",
    "        self.code = code\n",
    "        self.loop_stack = []  # Holds tuples for break/continue statements\n",
    "\n",
    "\n",
    "    # Generate a detailed label by traversing the node's children\n",
    "    def generate_label(self, node):\n",
    "        if node.type == \"expression_statement\":\n",
    "            return node.type\n",
    "        if node.type == \"parenthesized_expression\":\n",
    "            # Use only the labels of the child nodes\n",
    "            return ''.join(self.generate_label(child) for child in node.children)\n",
    "        if node.child_count == 0:  # Leaf node\n",
    "            return node.type\n",
    "        else:  # Non-leaf node\n",
    "            return ''.join(self.generate_label(child) for child in node.children)\n",
    "\n",
    "    def get_text(self, node):\n",
    "        \"\"\"\n",
    "        Get the text of a node in the AST.\n",
    "        \n",
    "        Parameters\n",
    "        ---\n",
    "        node: `Tree Sitter Node` The node to get the text from.\n",
    "        \n",
    "        Returns\n",
    "        ---\n",
    "        text: `str` The text of the node.\n",
    "        \"\"\"\n",
    "        line = self.code[node.start_byte:node.end_byte].decode(\"utf-8\")\n",
    "        return line \n",
    "\n",
    "    def new_node(self, node, label:str):\n",
    "        \"\"\"\n",
    "        Create a new node in the graph with a unique index and label.\n",
    "\n",
    "        Parameters\n",
    "        ---\n",
    "        label: `str` The label for the new node.\n",
    "        \n",
    "        Returns\n",
    "        ---\n",
    "        idx: `int` The index of the new node.\n",
    "        \"\"\"\n",
    "        idx = self.counter\n",
    "        # label = self.generate_label(node)\n",
    "        # # label = node.type\n",
    "        # #  # Append additional text for leaf nodes\n",
    "        # # if node.child_count == 0 and node.text:\n",
    "        # #     label += f\": {node.text.decode('utf8')}\"\n",
    "        self.graph.add_node(idx, label=label)\n",
    "        self.counter += 1\n",
    "        return idx\n",
    "\n",
    "    def connect_all(self, from_nodes, to_node):\n",
    "        \"\"\"\n",
    "        Connect all nodes `from_nodes` -> `to_node`.\n",
    "        \n",
    "        Parameters\n",
    "        ---\n",
    "        from_nodes: `list` The list of nodes to connect from.\n",
    "        \n",
    "        to_node: `int` The node to connect to.\n",
    "        \"\"\"\n",
    "        for n in from_nodes:\n",
    "            self.graph.add_edge(n, to_node)\n",
    "\n",
    "    def build_from_ast(self, node):\n",
    "        \"\"\"\n",
    "        Build the CFG from the AST node.\n",
    "        \n",
    "        Parameters\n",
    "        ---\n",
    "        node: `Tree Sitter Node` The root node of the AST.\n",
    "        \"\"\"\n",
    "        return self._visit(node)\n",
    "\n",
    "    def _visit(self, node):\n",
    "        \"\"\"\n",
    "        Visit a node in the AST and build the CFG.\n",
    "        \n",
    "        Parameters\n",
    "        ---\n",
    "        node: `Tree Sitter Node` The node to visit.\n",
    "        \n",
    "        Returns\n",
    "        ---\n",
    "        entry: `int` The entry node of the CFG.\n",
    "        \n",
    "        exit: `list` The exit nodes of the CFG.\n",
    "        \"\"\"\n",
    "        if node.type == \"block\":\n",
    "            prev_exit = []\n",
    "            entry = None\n",
    "            for child in node.children:\n",
    "                if child.is_named:\n",
    "                    subgraph = self._visit(child)\n",
    "                    if entry is None:\n",
    "                        entry = subgraph[\"entry\"]\n",
    "                    if prev_exit:\n",
    "                        self.connect_all(prev_exit, subgraph[\"entry\"])\n",
    "                    prev_exit = subgraph[\"exit\"]\n",
    "            return {\"entry\": entry, \"exit\": prev_exit}\n",
    "\n",
    "        elif node.type == \"if_statement\":\n",
    "            cond_node = self.new_node(node, f\"if {self.get_text(node.child_by_field_name('condition'))}\")\n",
    "            then_branch = self._visit(node.child_by_field_name(\"consequence\"))\n",
    "            else_node = node.child_by_field_name(\"alternative\")\n",
    "            if else_node:\n",
    "                else_branch = self._visit(else_node)\n",
    "                self.graph.add_edge(cond_node, then_branch[\"entry\"])\n",
    "                self.graph.add_edge(cond_node, else_branch[\"entry\"])\n",
    "                exits = then_branch[\"exit\"] + else_branch[\"exit\"]\n",
    "            else:\n",
    "                self.graph.add_edge(cond_node, then_branch[\"entry\"])\n",
    "                exits = then_branch[\"exit\"] + [cond_node]\n",
    "            return {\"entry\": cond_node, \"exit\": exits}\n",
    "\n",
    "        elif node.type == \"while_statement\":\n",
    "            cond_node = self.new_node(node, f\"while {self.get_text(node.child_by_field_name('condition'))}\")\n",
    "            \n",
    "            self.loop_stack.append((cond_node, []))  # Track exits for break\n",
    "            \n",
    "            body = self._visit(node.child_by_field_name(\"body\"))\n",
    "            self.graph.add_edge(cond_node, body[\"entry\"])\n",
    "            self.connect_all(body[\"exit\"], cond_node)\n",
    "            \n",
    "            _, break_exits = self.loop_stack.pop() # Track exits for break\n",
    "            \n",
    "            return {\"entry\": cond_node, \"exit\": break_exits + [cond_node]}\n",
    "        \n",
    "        elif node.type == \"do_statement\":\n",
    "            body_node = node.child_by_field_name(\"body\")\n",
    "            cond_node = self.new_node(node, f\"while {self.get_text(node.child_by_field_name('condition'))}\")\n",
    "\n",
    "            self.loop_stack.append((cond_node, []))\n",
    "\n",
    "            body = self._visit(body_node)\n",
    "\n",
    "            self.connect_all(body[\"exit\"], cond_node)  # Body to condition\n",
    "            self.graph.add_edge(cond_node, body[\"entry\"])  # Loop back if condition true\n",
    "\n",
    "            _, break_exits = self.loop_stack.pop()\n",
    "            return {\"entry\": body[\"entry\"], \"exit\": break_exits + [cond_node]}\n",
    "\n",
    "        elif node.type == \"for_statement\":\n",
    "            init = self.new_node(node, self.get_text(node.child_by_field_name(\"init\")))\n",
    "            cond = self.new_node(node, f\"for {self.get_text(node.child_by_field_name('condition'))}\")\n",
    "            update = self.new_node(node, self.get_text(node.child_by_field_name(\"update\")))\n",
    "\n",
    "            self.loop_stack.append((cond, []))  # Track exits for break\n",
    "\n",
    "            body = self._visit(node.child_by_field_name(\"body\"))\n",
    "\n",
    "            self.graph.add_edge(init, cond)\n",
    "            self.graph.add_edge(cond, body[\"entry\"])\n",
    "            self.connect_all(body[\"exit\"], update)\n",
    "            self.graph.add_edge(update, cond)\n",
    "\n",
    "            _, break_exits = self.loop_stack.pop() # Track exits for break\n",
    "            \n",
    "            return {\"entry\": init, \"exit\": break_exits + [cond]}\n",
    "        \n",
    "        elif node.type == \"switch_statement\":\n",
    "            cond_node = self.new_node(node, f\"switch {self.get_text(node.child_by_field_name('condition'))}\")\n",
    "            body = node.child_by_field_name(\"body\")  # should be a block\n",
    "            case_entries = []\n",
    "            last_exits = []\n",
    "\n",
    "            for child in body.children:\n",
    "                if child.type in {\"switch_label\", \"case\", \"default\"}:\n",
    "                    label = self.new_node(child, self.get_text(child))\n",
    "                    self.graph.add_edge(cond_node, label)\n",
    "                    case_entries.append(label)\n",
    "                    last_label = label\n",
    "                    last_exits = [label]\n",
    "                elif child.is_named:\n",
    "                    subgraph = self._visit(child)\n",
    "                    self.connect_all(last_exits, subgraph[\"entry\"])\n",
    "                    last_exits = subgraph[\"exit\"]\n",
    "\n",
    "            return {\"entry\": cond_node, \"exit\": last_exits}\n",
    "\n",
    "        elif node.type == \"try_statement\":\n",
    "            try_block = self._visit(node.child_by_field_name(\"block\"))\n",
    "            exits = try_block[\"exit\"]\n",
    "\n",
    "            # Handle catch clauses\n",
    "            catch_clauses = [c for c in node.children if c.type == \"catch_clause\"]\n",
    "            for catch in catch_clauses:\n",
    "                catch_block = self._visit(catch.child_by_field_name(\"block\"))\n",
    "                self.connect_all([try_block[\"entry\"]], catch_block[\"entry\"])\n",
    "                exits += catch_block[\"exit\"]\n",
    "\n",
    "            # Handle finally\n",
    "            finally_block = node.child_by_field_name(\"finally_clause\")\n",
    "            if finally_block:\n",
    "                final_graph = self._visit(finally_block.child_by_field_name(\"block\"))\n",
    "                self.connect_all(exits, final_graph[\"entry\"])\n",
    "                exits = final_graph[\"exit\"]\n",
    "\n",
    "            return {\"entry\": try_block[\"entry\"], \"exit\": exits}\n",
    "        \n",
    "        elif node.type == \"break_statement\":\n",
    "            brk = self.new_node(\"break\")\n",
    "            if self.loop_stack:\n",
    "                _, break_targets = self.loop_stack[-1]\n",
    "                break_targets.append(brk)\n",
    "            return {\"entry\": brk, \"exit\": []}\n",
    "\n",
    "        elif node.type == \"continue_statement\":\n",
    "            cont = self.new_node(\"continue\")\n",
    "            if self.loop_stack:\n",
    "                loop_cond, _ = self.loop_stack[-1]\n",
    "                self.graph.add_edge(cont, loop_cond)\n",
    "            return {\"entry\": cont, \"exit\": []}\n",
    "\n",
    "\n",
    "        elif node.type == \"return_statement\":\n",
    "            ret = self.new_node(node, self.get_text(node))\n",
    "            return {\"entry\": ret, \"exit\": []}\n",
    "\n",
    "        else:\n",
    "            stmt = self.new_node(node, self.get_text(node))\n",
    "            return {\"entry\": stmt, \"exit\": [stmt]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_method_declaration(node):\n",
    "    \"\"\"\n",
    "    Recursively search for the first 'method_declaration' node in the AST.\n",
    "\n",
    "    Parameters:\n",
    "    ---\n",
    "    node: `Tree Sitter Node` The current node in the AST.\n",
    "\n",
    "    Returns:\n",
    "    ---\n",
    "    method_node: `Tree Sitter Node` The 'method_declaration' node if found, else None.\n",
    "    \"\"\"\n",
    "    if node.type == \"method_declaration\":\n",
    "        return node\n",
    "\n",
    "    for child in node.children:\n",
    "        result = find_method_declaration(child)\n",
    "        if result:\n",
    "            return result\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parser_grammar(parser, lang_grammar, path_grammar):\n",
    "    \"\"\"\n",
    "    Set the language grammar for the parser.\n",
    "\n",
    "    Parameters:\n",
    "    ---\n",
    "    parser: Parser\n",
    "        The Tree-sitter parser instance.\n",
    "\n",
    "    lang_grammar: str\n",
    "        The programming language grammar ('cpp' or 'java').\n",
    "\n",
    "    path_grammar: str\n",
    "        The path to the compiled grammar file.\n",
    "\n",
    "    Returns:\n",
    "    ---\n",
    "    None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parser.set_language(Language(path_grammar, lang_grammar))\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR]: Failed to load {lang_grammar} language grammar. {e}\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Opening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0ba2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the constants for the Parser\n",
    "lang_grammar = 'java'\n",
    "path_grammar = f'../domain/entities/grammars/{lang_grammar}.so'\n",
    "\n",
    "name_file = 'HelloWorld.java'\n",
    "path_file = f'../../resources/datasets/original/{lang_grammar}/{name_file}'\n",
    "\n",
    "# Initialize the parser\n",
    "parser = Parser()\n",
    "\n",
    "# Set the grammar for the parser\n",
    "set_parser_grammar(parser, lang_grammar, path_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read codes from the provided file path\n",
    "with open(path_file, 'rb') as f:\n",
    "    code = f.read()\n",
    "\n",
    "# Generate the AST for the provided code snippets\n",
    "tree = parser.parse(code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AST Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the list of nodes using DFS\n",
    "ast_nodes = dfs_ast(tree.root_node)\n",
    "\n",
    "# Output.txt\n",
    "printTreeNodes(ast_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a hyerarchical Tree from the AST\n",
    "hyerarch_tree = AST_toGraph(nx.DiGraph(), tree.root_node)\n",
    "\n",
    "# hyerarchical Tree Labels\n",
    "hyerarch_tree_labels = {n: d['label'] for n, d in hyerarch_tree.nodes(data=True)}\n",
    "\n",
    "# Draw the graph\n",
    "hyerarch_tree_labels_pos = hierarchy_pos(hyerarch_tree, root=0)\n",
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "nx.draw(hyerarch_tree, \n",
    "        hyerarch_tree_labels_pos, \n",
    "        labels=hyerarch_tree_labels, \n",
    "        node_color='lightblue', \n",
    "        node_size=1000, \n",
    "        font_size=8, \n",
    "        arrows=False)\n",
    "\n",
    "plt.title(\"AST\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CFG Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the method declaration node\n",
    "node_method = find_method_declaration(tree.root_node)\n",
    "\n",
    "if node_method is None:\n",
    "    print(\"[ERROR]: No method_declaration found in the AST.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Build the CFG from the method body\n",
    "node_body = node_method.child_by_field_name(\"body\")\n",
    "\n",
    "# Initialize the CFGBuilder\n",
    "cfg_builder = CFGBuilder(code)\n",
    "cfg = cfg_builder.build_from_ast(node_body)\n",
    "cfgGraph = cfg_builder.graph\n",
    "\n",
    "# Visualization\n",
    "cfgGraph_pos = nx.spring_layout(cfgGraph)\n",
    "cfgGraph_labels = nx.get_node_attributes(cfgGraph, 'label')\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "nx.draw(cfgGraph, \n",
    "        cfgGraph_pos, \n",
    "        with_labels=True, \n",
    "        labels=cfgGraph_labels, \n",
    "        node_size=2500, \n",
    "        node_color='lightgreen', \n",
    "        font_size=9, \n",
    "        arrows=True)\n",
    "plt.title(\"Java Control Flow Graph (CFG)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Markov Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transition_matrix(G):\n",
    "    \"\"\"\n",
    "    Build a transition matrix from the given directed graph.\n",
    "\n",
    "    Parameters\n",
    "    ---\n",
    "    G: `Graph` The directed graph to build the transition matrix from.\n",
    "    \n",
    "    Returns\n",
    "    ---\n",
    "    matrix: `numpy.ndarray` The transition matrix.\n",
    "    \n",
    "    idx_map: `dict` A mapping from node labels to indices in the matrix.\n",
    "    \"\"\"\n",
    "    nodes = list(G.nodes)\n",
    "    idx_map = {node: i for i, node in enumerate(nodes)}\n",
    "    size = len(nodes)\n",
    "    matrix = np.zeros((size, size))\n",
    "\n",
    "    for src, dst in G.edges():\n",
    "        i, j = idx_map[src], idx_map[dst]\n",
    "        matrix[i][j] += 1\n",
    "\n",
    "    # Normalize rows to get probabilities\n",
    "    row_sums = matrix.sum(axis=1, keepdims=True)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        matrix = np.divide(matrix, row_sums, where=row_sums != 0)\n",
    "\n",
    "    return matrix, idx_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_similarity(A, B):\n",
    "    \"\"\"\n",
    "    Calculate the similarity between two matrices using the Frobenius norm.\n",
    "\n",
    "    Parameters\n",
    "    ---\n",
    "    A: `numpy.ndarray` The first matrix.\n",
    "    \n",
    "    B: `numpy.ndarray` The second matrix.\n",
    "    \n",
    "    Returns\n",
    "    ---\n",
    "    similarity: `float` The Frobenius norm of the difference between the two matrices.\n",
    "    \"\"\"\n",
    "    # Make sure both matrices are the same shape\n",
    "    size = max(A.shape[0], B.shape[0])\n",
    "    A_padded = np.zeros((size, size))\n",
    "    B_padded = np.zeros((size, size))\n",
    "    A_padded[:A.shape[0], :A.shape[1]] = A\n",
    "    B_padded[:B.shape[0], :B.shape[1]] = B\n",
    "\n",
    "    return np.linalg.norm(A_padded - B_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def flatten_transition_matrix(G):\n",
    "    \"\"\"\n",
    "    Flatten the transition matrix of the given directed graph.\n",
    "\n",
    "    Parameters\n",
    "    ---\n",
    "    G: `Graph` The directed graph to build the transition matrix from.\n",
    "\n",
    "    Returns\n",
    "    ---\n",
    "    matrix: `numpy.ndarray` The flattened transition matrix.\n",
    "    \"\"\"\n",
    "    # Build the transition matrix\n",
    "    matrix, _ = build_transition_matrix(G)\n",
    "    return matrix.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cfg_cosine_similarity(cfg1, cfg2):\n",
    "    \"\"\"\n",
    "    Calculate the cosine similarity between two CFGs.\n",
    "\n",
    "    Parameters\n",
    "    ---\n",
    "    cfg1: `Graph` The first CFG.\n",
    "    \n",
    "    cfg2: `Graph` The second CFG.\n",
    "    \n",
    "    Returns\n",
    "    ---\n",
    "    similarity: `float` The cosine similarity between the two CFGs.\n",
    "    \"\"\"\n",
    "    vec1 = flatten_transition_matrix(cfg1).reshape(1, -1)\n",
    "    vec2 = flatten_transition_matrix(cfg2).reshape(1, -1)\n",
    "\n",
    "    # Pad to same size if needed\n",
    "    max_len = max(vec1.shape[1], vec2.shape[1])\n",
    "    vec1 = np.pad(vec1, ((0, 0), (0, max_len - vec1.shape[1])))\n",
    "    vec2 = np.pad(vec2, ((0, 0), (0, max_len - vec2.shape[1])))\n",
    "\n",
    "    return cosine_similarity(vec1, vec2)[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read codes from the provided file path\n",
    "name_file1 = 'HelloWorld.java'\n",
    "name_file2 = 'HelloWorld2.java'\n",
    "\n",
    "path_file1 = f'../../resources/datasets/original/{lang_grammar}/{name_file1}'\n",
    "path_file2 = f'../../resources/datasets/original/{lang_grammar}/{name_file2}'\n",
    "\n",
    "with open(path_file1, 'rb') as f1:\n",
    "    code1 = f1.read()\n",
    "\n",
    "with open(path_file2, 'rb') as f2:\n",
    "    code2 = f2.read()\n",
    "\n",
    "# Generate the AST for the provided code snippets\n",
    "tree1 = parser.parse(code1)\n",
    "tree2 = parser.parse(code2)\n",
    "\n",
    "# Find the method declaration node\n",
    "node_method1 = find_method_declaration(tree1.root_node)\n",
    "node_method2 = find_method_declaration(tree2.root_node)\n",
    "\n",
    "if node_method1 is None or node_method2 is None:\n",
    "    print(\"[ERROR]: Method declaration not found in one or both files.\")\n",
    "\n",
    "# Build the CFG from the method body\n",
    "node_body1 = node_method1.child_by_field_name(\"body\")\n",
    "node_body2 = node_method2.child_by_field_name(\"body\")\n",
    "\n",
    "# Initialize the CFGBuilder for both files\n",
    "cfg_builder1 = CFGBuilder(code1)\n",
    "cfg1 = cfg_builder1.build_from_ast(node_body1)\n",
    "cfgGraph1 = cfg_builder1.graph\n",
    "\n",
    "\n",
    "cfg_builder2 = CFGBuilder(code2)\n",
    "cfg2 = cfg_builder2.build_from_ast(node_body2)\n",
    "cfgGraph2 = cfg_builder2.graph\n",
    "\n",
    "# Build transition matrices for both CFGs\n",
    "matrix1, _ = build_transition_matrix(cfgGraph1)\n",
    "matrix2, _ = build_transition_matrix(cfgGraph2)\n",
    "\n",
    "# Calculate the similarity between the two matrices\n",
    "simil_m1m2 = cfg_cosine_similarity(cfgGraph1, cfgGraph2)\n",
    "print(f\"Similarity between the two CFGs: {simil_m1m2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GED (Aproximate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_approximate_ged(cfg1, cfg2, timeout=15.0):\n",
    "    \"\"\"\n",
    "    Compute the approximate Graph Edit Distance between two CFGs using NetworkX.\n",
    "    \n",
    "    Parameters:\n",
    "        cfg1, cfg2: `networkx.DiGraph`\n",
    "        Objects representing the control flow graphs\n",
    "        \n",
    "        timeout: Maximum time (in seconds) to spend trying to compute the GED\n",
    "    \n",
    "    Returns:\n",
    "        A float representing the approximate GED, or None if it fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ged = nx.graph_edit_distance(\n",
    "            cfg1, cfg2, \n",
    "            node_match=nx.isomorphism.categorical_node_match('label', default=''),\n",
    "            edge_match=nx.isomorphism.categorical_edge_match('type', default=''),\n",
    "            timeout=timeout\n",
    "        )\n",
    "\n",
    "        if ged is None:\n",
    "            return None  # Timeout or no result\n",
    "\n",
    "        # Estimate max possible GED (very rough upper bound: sum of nodes + edges)\n",
    "        max_ged = (\n",
    "            cfg1.number_of_nodes() + cfg2.number_of_nodes() +\n",
    "            cfg1.number_of_edges() + cfg2.number_of_edges()\n",
    "        )\n",
    "\n",
    "        similarity = 1 - (ged / max_ged) if max_ged > 0 else 0.0\n",
    "        return round(similarity, 4)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during GED computation: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ged_score = compute_approximate_ged(cfgGraph1, cfgGraph2)\n",
    "\n",
    "if ged_score is not None:\n",
    "    print(f\"GED-based similarity: {ged_score:.4f}\")\n",
    "else:\n",
    "    print(\"Could not compute similarity (timeout or error).\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
